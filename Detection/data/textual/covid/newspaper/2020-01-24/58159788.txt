After criticism, federal officials to revisit policy for reviewing risky virus experiments 
 A long-running debate over U.S. government-funded research that tweaks risky pathogens in ways that could make them more dangerous to humans—is flaring up again. This time, at issue is whether officials should make public the work of a closed-door federal committee that weighs the risks and benefits of experiments proposed for funding by the National Institutes of Health (NIH), and in the past 2 years has greenlighted two controversial avian influenza studies.

That panel should make public the names of its members, as well as the reviews it writes, some scientists argued yesterday at a 2-day meeting of an expert panel that advises the Department of Health and Human Services (HHS). But doing so could breach NIH’s confidentiality rules for grant reviews, U.S. officials noted.

HHS and NIH officials, however, say they are open to some change to the review process, noting that the current emergence of a new virus in China underscores the importance of a smooth process for approving such studies. “If [the policy] needs to be fixed, we’ll fix it,” said Christian Hassell, senior science adviser to the HHS Office of the Assistant Secretary for Preparedness and Response.

The discussion is the latest chapter in a debate sparked in 2011 when two NIH-funded labs revealed they had modified the H5N1 avian influenza virus, which normally affects birds, to enable it to spread between ferrets. Such gain-of-function (GOF) experiments could help scientists better anticipate and prepare for pandemics. But critics worried that if such a lab virus were accidentally or deliberately released, it could spark a global outbreak.

After a 1-year voluntary research moratorium on such studies, in October 2014, the United States halted NIH funding for 18 GOF studies on avian influenza and the severe acute respiratory syndrome and Middle East respiratory syndrome coronaviruses for further discussion. (Some studies were later exempted from the moratorium.)

A panel called the National Science Advisory Board for Biosecurity (NSABB) then spent months hammering out a new process for weighing the risk and benefits of such GOF studies that could make a pathogen more likely to spread and cause serious disease in humans. That led to a December 2017 HHS review framework for research on what the government now called enhanced potential pandemic pathogens (EPPPs). The policy stipulates that after a proposed EPPP experiment passes NIH scientific peer review, an HHS panel of federal officials with wide-ranging expertise weighs the risks and benefits. If the committee approves, it can then receive NIH funding.

Then nearly 1 year ago, reported that the HHS review panel had approved two H5N1 projects in labs in Wisconsin and the Netherlands—the same labs that launched the controversy in 2011. The news infuriated opponents of such research, and they slammed federal officials for not disclosing the approvals in an op-ed in . HHS and NIH soon publicized the two approved projects but did not release the risk reviews.

This week, HHS reconvened NSABB for the first time in more than 2 years to look at ways to increase transparency. Hassell, who chairs the HHS risk review committee and is now assessing a third influenza project, defended the committee’s work. “This isn’t some rubber stamp,” but “a very tough group” that includes active researchers from various agencies, Hassell said. He worried that disclosing its members’ names could “chill” people from serving. Still, he said HHS is open to a range of possible changes to the EPPP review process, from better publicizing its decisions to adding nongovernment scientists to the committee, even if some steps require new action by Congress. “We are committed to enhancing transparency,” Hassell said.

Scientists calling for more openness about the committee’s work explained their reasoning to NSABB: to make sure committee members are “conflict-free” and “have the right skill set,” and so the public will understand why the work was approved, said Thomas Inglesby, director of the Center for Health Security at the Johns Hopkins University Bloomberg School of Public Health. Inglesby would also like risk reviews to undergo a public comment period before final approval of a project.

Disclosing details of the proposed research would go against federal rules requiring that unfunded proposals be kept confidential to protect propriety information such as intellectual property and trade secrets, noted Carrie Wolinetz, NIH associate director for science policy. But another EPPP opponent argued that standards should be different for such potentially risky research. “It seems perfectly reasonable to say that … if you want to do this kind of science, you sacrifice something” because “there are people 3000 miles away” who might be affected if a pathogen escaped, said Harvard University epidemiologist Marc Lipsitch.

Some NSABB members worried, however, that adding more steps to the review process could slow urgent research. Mark Denison of Vanderbilt University asked what would happen if a researcher wanted to adapt the coronavirus behind the current outbreak in Wuhan, China, to infect mice so that the animals could be used as models to study the virus. That work would be considered EPPP research. Wolinetz noted that such studies could be exempted from full review for public health reasons.

NIH is asking NSABB to develop recommendations on balancing security and transparency about the EPPP research reviews by early summer. NIH is also requesting a review of how the EPPP policy fits into other regulations governing dual use research of concern, or research that could be used to cause harm, by spring 2021.

Wolintez told that some disclosure of risk reviews “might make sense” to reassure the public that the committee took its work “very seriously.” But, “If the purpose is to give the public some ability to jump in and say, ‘This wasn’t rigorous enough, stop the presses,’ I suspect that is more problematic.”