{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d84d91",
   "metadata": {},
   "source": [
    "# Detection Module\n",
    "\n",
    "    The main goal of the detection module is to use the gazetteers out of the ontologies used to enrich PropaPhen into PropaPhen+ to discover relationships between network nodes/systems and the gufo:Entities by text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110efc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ceac9",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50975ef2",
   "metadata": {},
   "source": [
    "### Installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d1a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install tqdm\n",
    "#!pip install nltk\n",
    "#!pip install gatenlp\n",
    "#!pip install py4j\n",
    "#!pip install pyodide\n",
    "#!pip install ipywidgets\n",
    "#!pip install neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d43728",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f5246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaeaacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gatenlp import Document\n",
    "from gatenlp.gateworker import GateWorker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438eb90",
   "metadata": {},
   "source": [
    "### Custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6729226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('lib/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7296f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection.relationshipextraction import RelationshipDiscovery, GateExtractor, CleanDicts, rmToRelationCSV\n",
    "from detection.schema import Term, Concept, df_to_concepts, cleaningPlaceStr, conceptsToGazetteer\n",
    "from detection.worldumls import umlsConceptCleanner, isEnglish, worldConceptCleanner\n",
    "from detection.worldumls import ClearnWorldKGGazetteer\n",
    "#import detection.observationclustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa39dd",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a0d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_covid_journals = \"data/textual/covid/newspaper/\"\n",
    "path_to_kb_gazetteer = '../data/gazetteers/kbgazetteer.csv'\n",
    "path_to_netwoork_gazetteer = '../data/gazetteers/world_gazetteer_en.csv'\n",
    "path_to_lsts = \"data/lst/\"\n",
    "path_to_relation_folder = \"../data/neo4j/\"\n",
    "path_to_journalobservationcsv = \"../data/neo4j/observations_journal.csv\"\n",
    "path_to_medicalobservationcsv = \"../data/neo4j/observations_medical.csv\"\n",
    "path_to_socialobservationcsv = \"../data/neo4j/observations_social.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f1ea4",
   "metadata": {},
   "source": [
    "## Relationship Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e82cd",
   "metadata": {},
   "source": [
    "### KB Gazetteers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560db393",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_concept_list = []\n",
    "network_concept_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d665080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kb = pd.read_csv(path_to_kb_gazetteer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efb8f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C0026106</td>\n",
       "      <td>Mild mental retardation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C0026351</td>\n",
       "      <td>Moderate mental retardation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C0036857</td>\n",
       "      <td>Severe mental retardation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C0020796</td>\n",
       "      <td>Profound mental retardation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C0025362</td>\n",
       "      <td>Unspecified mental retardation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        ID                            Name\n",
       "0           0  C0026106         Mild mental retardation\n",
       "1           1  C0026351     Moderate mental retardation\n",
       "2           2  C0036857       Severe mental retardation\n",
       "3           3  C0020796     Profound mental retardation\n",
       "4           4  C0025362  Unspecified mental retardation"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c71050a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12620098it [13:09, 15993.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Term list\n"
     ]
    }
   ],
   "source": [
    "kb_concept_list = df_to_concepts(df_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22d91e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 7892473/7892473 [00:35<00:00, 220861.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(kb_concept_list))):\n",
    "    kb_concept_list[i] = umlsConceptCleanner(kb_concept_list[i])\n",
    "    kb_concept_list[i] = umlsConceptCleanner(kb_concept_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41aba865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 7892473/7892473 [02:19<00:00, 56774.96it/s]\n"
     ]
    }
   ],
   "source": [
    "umlsdict = conceptsToGazetteer(kb_concept_list,path_to_lsts+\"umls.lst\",cleaningPlaceStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21f141",
   "metadata": {},
   "source": [
    "### Place Gazetteers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6bdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network = pd.read_csv(path_to_netwoork_gazetteer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "834eefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "washingtonRemoveDoubles = ('wkg:158368533', \"Washington\")\n",
    "bradFord = (\"wkg:26701367\",\"Bradford\")\n",
    "def removeDoublesInNet(df_network,tupleList):\n",
    "    list_id_to_remove = []\n",
    "    for index, row in df_network.iterrows():\n",
    "        for tupleRemoveDoubles in tupleList:\n",
    "            if tupleRemoveDoubles[1] in row['Name'] and row['ID']!= tupleRemoveDoubles[0]:\n",
    "                list_id_to_remove.append(row['ID'])\n",
    "\n",
    "    df_network = df_network.drop(df_network[df_network.ID.isin(list_id_to_remove)].index.tolist())\n",
    "    return df_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66929659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network = removeDoublesInNet(df_network, [washingtonRemoveDoubles,bradFord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc09a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_net_list = ['\"Nga\"', '\"Centre\"', '\"Kou\"', '\"San\"','\"Real\"',\n",
    "                 '\"Vincent\"', '\"Lille\"','\"North\"', '\"Barr\"', '\"North\"'\n",
    "                 ,'\"South\"','\"West\"','\"East\"','\"Brito\"', '\"Utrecht\"', '\"Bush\"',\n",
    "                 '\"Bush\"', '\"Republic\"','\"Union\"', '\"Time\"',\n",
    "                 '\"Institute\"','\"Carbon\"','\"Center\"','\"Delhi\"','\"Mendenhall\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26be0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network = ClearnWorldKGGazetteer(df_network,clear_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d60d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wkg:10</td>\n",
       "      <td>\"Mamassita\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wkg:10</td>\n",
       "      <td>\"Mamacita\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wkg:1000709658</td>\n",
       "      <td>\"Boulzazen\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wkg:1000709658</td>\n",
       "      <td>\"Boulzazen\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wkg:1000709660</td>\n",
       "      <td>\"Tizi El Oued\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              ID            Name\n",
       "0           0          wkg:10     \"Mamassita\"\n",
       "1           1          wkg:10      \"Mamacita\"\n",
       "2           2  wkg:1000709658     \"Boulzazen\"\n",
       "3           3  wkg:1000709658     \"Boulzazen\"\n",
       "4           4  wkg:1000709660  \"Tizi El Oued\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_network.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e0a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1692247it [01:41, 16624.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Term list\n"
     ]
    }
   ],
   "source": [
    "network_concept_list = df_to_concepts(df_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e35554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing network\n",
    "#for i in tqdm(range(len(network_concept_list))):\n",
    "#    network_concept_list[i] = worldConceptCleanner(network_concept_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ccbe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usual name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 948962/948962 [00:03<00:00, 308038.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "print(\"Usual name\")\n",
    "normalplacesdict = conceptsToGazetteer(network_concept_list,path_to_lsts+\"places.lst\",cleaningPlaceStr)\n",
    "# Cap\n",
    "#print(\"Cap name\")\n",
    "#capdict = conceptsToGazetteer(network_concept_list,path_to_lsts+\"places_cap.lst\",capPlaceStr)\n",
    "# Lower\n",
    "#print(\"Lower name\")\n",
    "#lowerdict = conceptsToGazetteer(network_concept_list,path_to_lsts+\"places_lower.lst\",lowerPlaceStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd1b0e",
   "metadata": {},
   "source": [
    "### GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ade2519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 01:24:04,601|ERROR|py4j.java_gateway|An error occurred while trying to connect to the Java server (127.0.0.1:25333)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 982, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1132, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:25333)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:982\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1132\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[43mGateWorker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1234\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/gatenlp/gateworker/gateworker.py:405\u001b[0m, in \u001b[0;36mGateWorker.__init__\u001b[0;34m(self, port, retry_ports, start, java, host, gatehome, platform, auth_token, use_auth_token, log_actions, keep, debug)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m JavaGateway(\n\u001b[1;32m    401\u001b[0m     gateway_parameters\u001b[38;5;241m=\u001b[39mGatewayParameters(port\u001b[38;5;241m=\u001b[39mport, auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_token)\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# do not wait until the gateway is used by the user to detect a problem, instead, retrieve the GATE\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# version here to check basic functionality\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_version\u001b[49m\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/gatenlp/gateworker/gateworker.py:437\u001b[0m, in \u001b[0;36mGateWorker.gate_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgate_version\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Return the GATE version of the connected GATE process.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate\u001b[49m\u001b[38;5;241m.\u001b[39mMain\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[1;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1712\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:984\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeque\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 984\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:990\u001b[0m, in \u001b[0;36mGatewayClient._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    988\u001b[0m     connection \u001b[38;5;241m=\u001b[39m GatewayConnection(\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property)\n\u001b[0;32m--> 990\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/data/dataRapide/gabriel/git/DDPF/Detection/dtvenv/lib/python3.8/site-packages/py4j/java_gateway.py:1144\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while trying to connect to the Java \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m   1143\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(msg)\n\u001b[0;32m-> 1144\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(msg, e)\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:25333)"
     ]
    }
   ],
   "source": [
    "gs = GateWorker(start=False, auth_token=\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def cleanKeys(dictionary, clean_list):\n",
    "    for c in clean_list:\n",
    "        if c in dictionary:\n",
    "            del dictionary[c]\n",
    "    return dictionary\n",
    "\n",
    "def CleanDicts(netdict,kbdict):\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    punctuation = [i for i in string.punctuation  ]\n",
    "    stopwords_list_maj = [s.title() for s in stopwords_list]\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\",\n",
    "              \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    months_lower = [m.lower() for m in months]\n",
    "    clean_list = stopwords_list + punctuation + list(\n",
    "        string.ascii_lowercase) + list(\n",
    "        string.ascii_uppercase) + stopwords_list_maj + months + months_lower\n",
    "    netdict = cleanKeys(netdict,clean_list) \n",
    "    kbdict = cleanKeys(kbdict,clean_list+list(netdict.keys()))\n",
    "    return netdict, kbdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c893e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalplacesdict, umlsdict = CleanDicts(normalplacesdict, umlsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82c956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gateExtractor = GateExtractor(umlsdict,normalplacesdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29edd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annie\n",
    "gs.worker.loadMavenPlugin(\"uk.ac.gate.plugins\", \"annie\", \"8.6\")\n",
    "# now load the prepared ANNIE pipeline from the plugin\n",
    "pipeline = gs.worker.loadPipelineFromPlugin(\"uk.ac.gate.plugins\",\"annie\", \"/resources/ANNIE_with_defaults.gapp\")\n",
    "pipeline.getName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e739724",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateExtractor.extra_pr['annie'] = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection.relationshipextraction import RelationMatrix\n",
    "\n",
    "class RMGenerator():\n",
    "    \n",
    "    def __init__(self, corpus,gateExtractor, gs):\n",
    "        self.corpus = corpus\n",
    "        self.gateExtractor = gateExtractor\n",
    "        self.gs = gs\n",
    "    \n",
    "    def directTermMatching(self, matrix_id):\n",
    "        rm = RelationMatrix(matrix_id)\n",
    "        # Per document\n",
    "        for doc in tqdm(self.corpus):\n",
    "            pdoc = self.gs.gdoc2pdoc(doc)\n",
    "            pdoc = self.gateExtractor.tokenizer(pdoc)\n",
    "            pdoc = self.gateExtractor.tok_gaz(pdoc)\n",
    "            # Making the rm links\n",
    "            for kb_annotation in pdoc.annset().with_type(\"kb\"):\n",
    "                for network_annoation in pdoc.annset().with_type(\"network\"):\n",
    "                    rm.increaseBy(self.gateExtractor.dict_kb[kb_annotation.features['key']], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            self.gs.del_resource(doc)\n",
    "        return rm\n",
    "    \n",
    "    def paragraphTermMatching(self, matrix_id):\n",
    "        assert 'annie' in self.gateExtractor.extra_pr.keys()\n",
    "        rm = RelationMatrix(matrix_id)\n",
    "        # Per document\n",
    "        for doc in tqdm(self.corpus):\n",
    "            # Run annie\n",
    "            if len(self.gs.gdoc2pdoc(doc).text) <= 0:\n",
    "                self.gs.del_resource(doc)\n",
    "                continue\n",
    "            self.gs.worker.run4Document(self.gateExtractor.extra_pr['annie'], doc)\n",
    "            pdoc = self.gs.gdoc2pdoc(doc)            \n",
    "            # Get network and kb\n",
    "            pdoc = self.gateExtractor.tok_gaz(pdoc)\n",
    "            # Get paragraph\n",
    "            praragraphann = pdoc.annset('Original markups').with_type(\"paragraph\")\n",
    "            # For each paragraph\n",
    "            for ann in praragraphann:\n",
    "                # Making the rm links\n",
    "                for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                        rm.increaseBy(self.gateExtractor.dict_kb[kb_annotation.features['key']], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            self.gs.del_resource(doc)\n",
    "        return rm\n",
    "    \n",
    "    def paragraphTermMatchingTransitivity(self, matrix_id):\n",
    "        assert 'annie' in self.gateExtractor.extra_pr.keys()\n",
    "        rm = RelationMatrix(matrix_id)\n",
    "        # Per document\n",
    "        for doc in tqdm(self.corpus):\n",
    "            # Run annie\n",
    "            if len(self.gs.gdoc2pdoc(doc).text) <= 0:\n",
    "                self.gs.del_resource(doc)\n",
    "                continue\n",
    "            self.gs.worker.run4Document(self.gateExtractor.extra_pr['annie'], doc)\n",
    "            pdoc = self.gs.gdoc2pdoc(doc)            \n",
    "            # Get network and kb\n",
    "            pdoc = self.gateExtractor.tok_gaz(pdoc)\n",
    "            # Get paragraph\n",
    "            paragraphann = pdoc.annset('Original markups').with_type(\"paragraph\")\n",
    "            dictKbToKb = {}\n",
    "            # For each paragraph\n",
    "            for ann in paragraphann:\n",
    "                # Making Refs between KB entities\n",
    "                for kb_annotation1 in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for kb_annotation2 in pdoc.annset().within(ann).with_type('kb'):\n",
    "                        # if same annotation continue\n",
    "                        if kb_annotation1 == kb_annotation2:\n",
    "                            continue\n",
    "                        # If empty list create list\n",
    "                        if kb_annotation1.features['key'] not in dictKbToKb:\n",
    "                                dictKbToKb[kb_annotation1.features['key']] = []\n",
    "                        # Add key to list\n",
    "                        dictKbToKb[kb_annotation1.features['key']] = dictKbToKb[\n",
    "                            kb_annotation1.features['key']] +  [kb_annotation2.features['key']]\n",
    "            for ann in paragraphann:\n",
    "                # Making the rm links\n",
    "                for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                        rm.increaseBy(self.gateExtractor.dict_kb[kb_annotation.features['key']], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            # Adding transitivity relations\n",
    "            for ann in paragraphann:\n",
    "                # Making the rm links\n",
    "                for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                    for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                        if kb_annotation.features['key'] not in dictKbToKb:\n",
    "                            continue\n",
    "                        for transitivityKey in dictKbToKb[kb_annotation.features['key']]:\n",
    "                            if rm.getValue(self.gateExtractor.dict_kb[transitivityKey], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']]) is None:\n",
    "                                # If link does not exists, then create one\n",
    "                                rm.increaseBy(self.gateExtractor.dict_kb[transitivityKey], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "                            \n",
    "            self.gs.del_resource(doc)\n",
    "        return rm\n",
    "    \n",
    "    def sentenceTermMatching(self, matrix_id):\n",
    "        assert 'annie' in self.gateExtractor.extra_pr.keys()\n",
    "        rm = RelationMatrix(matrix_id)\n",
    "        # Per document\n",
    "        for doc in tqdm(self.corpus):\n",
    "            # Run annie\n",
    "            if len(self.gs.gdoc2pdoc(doc).text) <= 0:\n",
    "                self.gs.del_resource(doc)\n",
    "                continue\n",
    "            self.gs.worker.run4Document(self.gateExtractor.extra_pr['annie'], doc)\n",
    "            pdoc = self.gs.gdoc2pdoc(doc)            \n",
    "            # Get network and kb\n",
    "            pdoc = self.gateExtractor.tok_gaz(pdoc)\n",
    "            # Get paragraph\n",
    "            sentenceann = pdoc.annset('').with_type(\"Sentence\")\n",
    "            # For each paragraph\n",
    "            for ann in sentenceann:\n",
    "                # Making the rm links\n",
    "                for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                        rm.increaseBy(self.gateExtractor.dict_kb[kb_annotation.features['key']], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            self.gs.del_resource(doc)\n",
    "        return rm\n",
    "    \n",
    "    def sentenceTermMatchingTransitivity(self, matrix_id):\n",
    "        assert 'annie' in self.gateExtractor.extra_pr.keys()\n",
    "        rm = RelationMatrix(matrix_id)\n",
    "        # Per document\n",
    "        for doc in tqdm(self.corpus):\n",
    "            # Run annie\n",
    "            if len(self.gs.gdoc2pdoc(doc).text) <= 0:\n",
    "                self.gs.del_resource(doc)\n",
    "                continue\n",
    "            self.gs.worker.run4Document(self.gateExtractor.extra_pr['annie'], doc)\n",
    "            pdoc = self.gs.gdoc2pdoc(doc)            \n",
    "            # Get network and kb\n",
    "            pdoc = self.gateExtractor.tok_gaz(pdoc)\n",
    "            # Get paragraph\n",
    "            sentenceann = pdoc.annset('').with_type(\"Sentence\")\n",
    "            dictKbToKb = {}\n",
    "            # For each paragraph\n",
    "            for ann in sentenceann:\n",
    "                # Making Refs between KB entities\n",
    "                for kb_annotation1 in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for kb_annotation2 in pdoc.annset().within(ann).with_type('kb'):\n",
    "                        # if same annotation continue\n",
    "                        if kb_annotation1 == kb_annotation2:\n",
    "                            continue\n",
    "                        # If empty list create list\n",
    "                        if kb_annotation1.features['key'] not in dictKbToKb:\n",
    "                                dictKbToKb[kb_annotation1.features['key']] = []\n",
    "                        # Add key to list\n",
    "                        dictKbToKb[kb_annotation1.features['key']] = dictKbToKb[\n",
    "                            kb_annotation1.features['key']] +  [kb_annotation2.features['key']]\n",
    "            # For each paragraph\n",
    "            for ann in sentenceann:\n",
    "                # Making the rm links\n",
    "                for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                    for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                        rm.increaseBy(self.gateExtractor.dict_kb[kb_annotation.features['key']], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            # Adding transitivity relations\n",
    "            for ann in sentenceann:\n",
    "                # Making the rm links\n",
    "                for network_annoation in pdoc.annset().within(ann).with_type('network'):\n",
    "                    for kb_annotation in pdoc.annset().within(ann).with_type('kb'):\n",
    "                        if kb_annotation.features['key'] not in dictKbToKb:\n",
    "                            continue\n",
    "                        for transitivityKey in dictKbToKb[kb_annotation.features['key']]:\n",
    "                            if rm.getValue(self.gateExtractor.dict_kb[transitivityKey], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']]) is None:\n",
    "                                # If link does not exists, then create one\n",
    "                                rm.increaseBy(self.gateExtractor.dict_kb[transitivityKey], \n",
    "                                self.gateExtractor.dict_network[network_annoation.features['key']],1)\n",
    "            self.gs.del_resource(doc)\n",
    "        return rm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f824bf",
   "metadata": {},
   "source": [
    "## Relationship Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b16de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusJournal = gs.getCorpus4Name('PreDiViD-Journal-11-19')\n",
    "rd = RelationshipDiscovery(corpusJournal, gateExtractor,gs)\n",
    "rmSentence = rd.rmGen.sentenceTermMatching('KES-PreDiViD-Journal-2019-11-Sentence')\n",
    "df_rmSentence = rmToRelationCSV(rmSentence, 'Journal', 1, 'hasPresence',cluster_date='2019-11') \n",
    "df_rmSentence.to_csv(path_to_relation_folder+rmSentence.matrix_id+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7eba92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpusMedical = gs.getCorpus4Name('PreDiViD-Medical-12-19')\n",
    "rd = RelationshipDiscovery(corpusMedical, gateExtractor,gs)\n",
    "rmSentence = rd.rmGen.sentenceTermMatching('KES-PreDiViD-Medical-2019-12-Sentence')\n",
    "df_rmSentence = rmToRelationCSV(rmSentence, 'Medical', 1, 'hasPresence',cluster_date='2019-12') \n",
    "df_rmSentence.to_csv(path_to_relation_folder+rmSentence.matrix_id+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938e707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpusSocial = gs.getCorpus4Name('PreDiViD-Social-2-22') # CORRECT corpus dates\n",
    "rd = RelationshipDiscovery(corpusSocial, gateExtractor,gs)\n",
    "rmSentence = rd.rmGen.sentenceTermMatching('KES-PreDiViD-Social-2020-20-Sentence')\n",
    "df_rmSentence = rmToRelationCSV(rmSentence, 'Social', 1, 'hasPresence',cluster_date='2020-02') \n",
    "df_rmSentence.to_csv(path_to_relation_folder+rmSentence.matrix_id+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf748b",
   "metadata": {},
   "source": [
    "## Transitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6afb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = gs.getCorpus4Name('PreDiViD')\n",
    "rmGen = RMGenerator(corpus, gateExtractor, gs)\n",
    "rd = RelationshipDiscovery(corpus, gateExtractor,gs,rmGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7991e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmSentence = rd.rmGen.sentenceTermMatchingTransitivity('PreDiViD-COVID-Journal-2019-11-Sentence-Transitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e619bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmParagraph = rd.rmGen.paragraphTermMatching('PreDiViD-COVID-Journal-2019-11-Paragraph-Transitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6958da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmParagraph = rmToRelationCSV(rmParagraph, 'Journal', 1, 'hasPresence',cluster_date='2019-11') \n",
    "df_rmParagraph.to_csv(path_to_relation_folder+rmParagraph.matrix_id+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmSentence = rmToRelationCSV(rmSentence, 'Journal', 1, 'hasPresence',cluster_date='2019-11') \n",
    "df_rmSentence.to_csv(path_to_relation_folder+rmSentence.matrix_id+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b7ab8",
   "metadata": {},
   "source": [
    "### Observation Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.kgce.schema.semantic.neo4jclasses import Neo4jRelation\n",
    "from lib.kgce.neo4j.handler import Neo4jWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4934a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Neo4jWrapper:\n",
    "\n",
    "    def __init__(self, uri, userName, password):\n",
    "        self.uri = uri\n",
    "        self.userName = userName\n",
    "        self.password = password\n",
    "        # Connect to the neo4j database server\n",
    "        self.graphDB_Driver  = GraphDatabase.driver(uri, auth=(userName, password)) \n",
    "        \n",
    "    def sendQuery(self, cql_commands):\n",
    "        result = []\n",
    "        done_queries = []\n",
    "        with self.graphDB_Driver.session() as graphDB_Session:\n",
    "            for cqlCreate in tqdm(cql_commands):\n",
    "                try:\n",
    "                    result += [graphDB_Session.run(cqlCreate).to_df()]\n",
    "                    done_queries.append(cqlCreate)\n",
    "                except Exception as e:\n",
    "                    tqdm.write(str(e))\n",
    "                    tqdm.write(cqlCreate)\n",
    "                    result += [str(e)]\n",
    "        return result\n",
    "    \n",
    "    def closeConnection(self):\n",
    "        self.graphDB_Driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06688534",
   "metadata": {},
   "outputs": [],
   "source": [
    "neowrapper = Neo4jWrapper(uri=\"bolt://localhost:7687\",userName=\"neo4j\",password=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neowrapper.sendQuery([\n",
    "    \"\"\"MATCH (n:Country)<-[r:hasPresence]-(c) \n",
    "    WHERE toInteger(r.intensity) >= 5 AND r.source = \"Journal\"\n",
    "    RETURN n.wkgs_nameEn as System_Name, n.id, c.name, c.id, r.intensity as intensity;\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963862da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_journal = result[0].groupby(['System_Name','n.id'],as_index=False).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29042d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045739b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neowrapper.sendQuery([\n",
    "    \"\"\"MATCH (n:Country)<-[r:hasPresence]-(c) \n",
    "    WHERE toInteger(r.intensity) >= 6 AND r.source = \"Medical\"\n",
    "    RETURN n.wkgs_nameEn as System_Name, n.id, c.name, c.id, r.intensity as intensity;\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f40131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_medical = result[0].groupby(['System_Name','n.id'],as_index=False).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f67726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neowrapper.sendQuery([\n",
    "    \"\"\"MATCH (n:Country)<-[r:hasPresence]-(c) \n",
    "    WHERE toInteger(r.intensity) >= 20 AND r.source = \"Social\"\n",
    "    RETURN n.wkgs_nameEn as System_Name, n.id, c.name, c.id, r.intensity as intensity;\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5617bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_social = result[0].groupby(['System_Name','n.id'],as_index=False).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeedfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ca32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "df_result_journal.to_csv(path_to_journalobservationcsv)\n",
    "df_result_medical.to_csv(path_to_medicalobservationcsv)\n",
    "df_result_social.to_csv(path_to_socialobservationcsv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtvenv",
   "language": "python",
   "name": "dtvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
